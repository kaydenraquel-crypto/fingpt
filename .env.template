# RunPod FinGPT Server Environment Configuration
# ==============================================

# API Configuration
FINGPT_API_KEY=runpod-fingpt-2024
IDLE_SHUTDOWN_MINUTES=30
MAX_BATCH_SIZE=4
ENABLE_AUTO_SHUTDOWN=true
CUDA_VISIBLE_DEVICES=0

# Python and Cache Paths (Volume Disk - CRITICAL for persistence!)
PYTHONPATH=/workspace:/workspace/FinGPT
HF_HOME=/workspace/.huggingface
TRANSFORMERS_CACHE=/workspace/.cache/transformers
HF_DATASETS_CACHE=/workspace/.cache/datasets
TORCH_HOME=/workspace/.cache/torch
PIP_CACHE_DIR=/workspace/.pip_cache

# Model and Data Paths (Volume Disk)
MODELS_DIR=/workspace/models
FINGPT_MODEL_PATH=/workspace/models/fingpt
DATA_DIR=/workspace/data

# Server Configuration
SERVER_HOST=0.0.0.0
SERVER_PORT=8003
LOG_LEVEL=info

# Ensure all paths are on persistent volume disk
WORKSPACE_DIR=/workspace
FINGPT_DIR=/workspace/FinGPT
SERVER_DIR=/workspace/fingpt_server
